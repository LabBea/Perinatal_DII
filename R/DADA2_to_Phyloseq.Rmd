---
title: "DADA2 through Phyloseq"
output: html_notebook
---
In this script, raw fastq files will be cleaned, aligned to reference genome and corrected for various effects. The initial data processing and clean up was based on the DADA2 pipeline found [here](https://benjjneb.github.io/dada2/tutorial.html). This dataset first needs to be filtered to only include the files of the samples with the corresponding diet data. Additionally, the sequences were analyzed in 5 separate batches and this effects will need to be accounted for. The workflow is listed below
  

# Workflow {.tabset}

__Step 1:__ Run DADA2 for all batches  

__Step 2:__ Convert to Phyloseq & Contaminant Removal  

__Step 3:__ Batch Correction and merge with COMBATseq

<br /> 

##### Load Library
Use devtools to install packages if problematic
```{r}
library(captioner)
library(here)
library(tidyverse)
library(devtools)
library(dada2)
library(sva)
library(phyloseq)
library(ape)
library(decontam)
```



## DADA2 - raw 16SRNA analysis
***  

### File Import

#### Mapfile  
Creation of the sample data: The Mapfile contains all information for each fastq file including the redcapid, sample type, batch number etc. This is what will be used to filter the fastq files to those of interest and later to create the sample data for phyloseq
```{r Mapfile-redcapid}
#Step 1: Import mapfile: contains IDs and description of the sample
#######################################################################
Mapfile <- read.csv(here::here("Data", "Microbiome_Data", "mapFile_PMH_05272021.csv"))


#Step 2: Filter Mapfile to only have redcapids from our diet data
#######################################################################
##Import list of redcapids (computed from the Diet analysis script)
redcapids <- read.csv(here::here("Data", "Microbiome_Data", "Diet_redcapids.csv"))
redcapids2 <- data.frame(redcapids[,-1])

#Filter Mapfile by Diet redcapids
filter1 <- redcapids2$redcapid
filter2 <- c(0,1)
Mapfile2 <- Mapfile %>%
  filter(ParticipantID %in% filter1) %>%
  filter(Visit %in% filter2)

#Step 3: Filter separate mapfile for the controls
#######################################################################

Mapfile3 <- filter(Mapfile, ParticipantID == "NONE")

#Remove Positive controls
Mapfile3 <- filter(Mapfile3, !(SampleName %in% c("Zymo_mock_A", "Zymo_mock_B",
                                                 "Zymo_mock_C", "Zymo_mock_D", 
                                                  "Zymo_mock_E", "Zymo_mock_F", "Zymo_mock_G", "Zymo_mock_H",
                                                 "Zymo_Mock_G4", "Zymo_Mock_G5", "Zymo_Mock_G6", "Zymo_Mock_G7", 
                                                 "Zymo_Mock_G8", "Zymo_Mock_G9", "Zymo_Mock_G10", "Zymo_Mock_G11",
                                                 "Zymo_Mock_G12")))


#Step 4: Merge the two filtered dataframes
#######################################################################
Mapfile4 <- merge(Mapfile2, Mapfile3, all = TRUE)

#Step 5: Add in what their FFQ type was
#######################################################################
FFQ_type <- read.csv(here("Data", "Blood Data","Date_FFQ_ID_HGB.csv"))
FFQ_type <- FFQ_type %>% rename("ParticipantID" = "redcapid")
Mapfile4 <- merge(Mapfile4, FFQ_type, by = "ParticipantID", all=TRUE)
Mapfile <- Mapfile4[,-c(42,44:46)]

#Add the controls back in 
Mapfile <- Mapfile <- merge(Mapfile, Mapfile3, all = TRUE)
Mapfile <- Mapfile[-c(168,169),]

#List of names to use to hard call the files we want
mapfile_comp <- Mapfile$SampleID 
mapfileF_comp <- paste(mapfile_comp, "R1.fastq", sep = "_")
```


#### Fastq file import and Selection  
Files used have already been split by sample into the forward and reverse files by batch. Since Batch4 is missing its reverse sequences, we excluded all reverse sequences from this analysis. Runs = batches. Batch 4 was excluded due to poor sequencing
```{r Data-Import}
#Step 1: Import Files &filter by mapfile names ###########################################
#Batch1
fnFs1 <- sort(list.files(here("Data", "Microbiome_Data", "fastq", "Run1SplitbySample", "R1"), 
                         pattern = paste0(mapfileF_comp, collapse="|"), full.names = TRUE))
#Batch2
fnFs2 <- sort(list.files(here("Data", "Microbiome_Data", "fastq", "Run2SplitBySample", "R1"), 
                         pattern = paste0(mapfileF_comp, collapse="|"), full.names = TRUE))

#Batch3
fnFs3 <- sort(list.files(here("Data", "Microbiome_Data", "fastq", "Run3SplitBySample", "R1"), 
                         pattern = paste0(mapfileF_comp, collapse="|"), full.names = TRUE))

#Batch5
fnFs5 <- sort(list.files(here("Data", "Microbiome_Data", "fastq", "Run5SplitbySample", "R1"), 
                         pattern = paste0(mapfileF_comp, collapse="|"), full.names = TRUE))

#Step 2: Prep the group stringsplit for later use ######################################
sample.names1 <- sapply(strsplit(basename(fnFs1), "_"), `[`, 1)
sample.names2 <- sapply(strsplit(basename(fnFs2), "_"), `[`, 1)
sample.names3 <- sapply(strsplit(basename(fnFs3), "_"), `[`, 1)
sample.names5 <- sapply(strsplit(basename(fnFs5), "_"), `[`, 1)

```


### Quality Plot Profiles  
__Green line:__ Mean quality score  
__Orange line:__ quartile of the quality score  
__Red line:__ scaled proportion of read going to the last position  

```{r Quality-profiles}
#Batch1
#######################################################################
plotQualityProfile(fnFs1)

#Batch2
#######################################################################
plotQualityProfile(fnFs2)

#Batch3
#######################################################################
plotQualityProfile(fnFs3)

#Batch5
#######################################################################
plotQualityProfile(fnFs5)

```



### Filter and Trim Sequences  
Trimmed & filtered sequences will be contained in one single folder in the Microbiome_Output folder. 
```{r Filter}
# Place filtered files in filtered/ subdirectory 

#Batch1
#######################################################################
filtFs1 <- file.path(here("Output", "Microbiome_Output"), "Run1filtered", paste0(sample.names1, "_F_filt.fastq.gz"))
names(filtFs1) <- sample.names1

out1 <- filterAndTrim(fnFs1, filtFs1, truncLen=150, trimLeft = 5,
              maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE)

#Batch2
#######################################################################
filtFs2 <- file.path(here("Output", "Microbiome_Output"), "Run2filtered", paste0(sample.names2, "_F_filt.fastq.gz"))
names(filtFs2) <- sample.names2

out2 <- filterAndTrim(fnFs2, filtFs2, truncLen=150, trimLeft = 5,
              maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE)

#Batch3
#######################################################################
filtFs3 <- file.path(here("Output", "Microbiome_Output"), "Run3filtered", paste0(sample.names3, "_F_filt.fastq.gz"))
names(filtFs3) <- sample.names3

out3 <- filterAndTrim(fnFs3, filtFs3, truncLen=150, trimLeft = 5,
              maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE)

#Batch5
#######################################################################
filtFs5 <- file.path(here("Output", "Microbiome_Output"), "Run5filtered", paste0(sample.names5, "_F_filt.fastq.gz"))
names(filtFs5) <- sample.names5

out5 <- filterAndTrim(fnFs5, filtFs5, truncLen=150, trimLeft = 5,
              maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE)

# Check how each batch was filtered
#######################################################################
head(out1)
head(out2)
head(out3)
head(out5)

```



### Learn Error Rates

```{r Learn-Error-Rates}
#Batch1
err1 <- learnErrors(filtFs1, multithread = TRUE)
#Batch2
err2 <- learnErrors(filtFs2, multithread = TRUE)
#Batch3
err3 <- learnErrors(filtFs3, multithread = TRUE)
#Batch5
err5 <- learnErrors(filtFs5, multithread = TRUE)

#Visualize the Error rates
plotErrors(err1, nominalQ = TRUE)
plotErrors(err2, nominalQ = TRUE)
plotErrors(err3, nominalQ = TRUE)
plotErrors(err5, nominalQ = TRUE)

```



### Sample Inference  
Unsure about the qualities of these reads
```{r Sample-Inference}
#Batch1
dadaFs1 <- dada(filtFs1, err=err1, multithread = TRUE)

#Batch2
dadaFs2 <- dada(filtFs2, err=err2, multithread = TRUE)

#Batch3
dadaFs3 <- dada(filtFs3, err=err3, multithread = TRUE)

#Batch5
dadaFs5 <- dada(filtFs5, err=err5, multithread = TRUE)

#inspect the dadaclass object??????? unsure about quality of these reads
dadaFs1[[1]]
dadaFs2[[1]]
dadaFs3[[1]]
dadaFs5[[1]]
```


### Construct Sequence Table
```{r Sequence-Table}
#Make sequence table for each batch
seqtabF1 <- makeSequenceTable(dadaFs1)
seqtabF2 <- makeSequenceTable(dadaFs2)
seqtabF3 <- makeSequenceTable(dadaFs3)
seqtabF5 <- makeSequenceTable(dadaFs5)

```



### Remove Chimeras
```{r Remove-Chimeras}
#Batch1
seqtab1.nochim <- removeBimeraDenovo(seqtabF1, method="consensus", multithread = TRUE, verbose= TRUE)
sum(seqtab1.nochim)/sum(seqtabF1)

#Batch2
seqtab2.nochim <- removeBimeraDenovo(seqtabF2, method="consensus", multithread = TRUE, verbose= TRUE)
sum(seqtab2.nochim)/sum(seqtabF2)

#Batch3
seqtab3.nochim <- removeBimeraDenovo(seqtabF3, method="consensus", multithread = TRUE, verbose= TRUE)
sum(seqtab3.nochim)/sum(seqtabF3)

#Batch5
seqtab5.nochim <- removeBimeraDenovo(seqtabF5, method="consensus", multithread = TRUE, verbose= TRUE)
sum(seqtab5.nochim)/sum(seqtabF5)

```




### Track Reads Through Pipeline
```{r Track-Reads}
#Step 1: Set chunk functions for all Batches
#######################################################################
getN <- function(x) sum(getUniques(x))


#Step 2: Track across all Batches
#######################################################################

#Batch1
track1 <- cbind(out1, sapply(dadaFs1, getN), rowSums(seqtab1.nochim))
colnames(track1) <- c("input", "filtered", "denoisedF", "nonchim")
rownames(track1) <- sample.names1
head(track1)

#Batch2
track2 <- cbind(out2, sapply(dadaFs2, getN), rowSums(seqtab2.nochim))
colnames(track2) <- c("input", "filtered", "denoisedF", "nonchim")
rownames(track2) <- sample.names2
head(track2)

#Batch3
track3 <- cbind(out3, sapply(dadaFs3, getN), rowSums(seqtab3.nochim))
colnames(track3) <- c("input", "filtered", "denoisedF", "nonchim")
rownames(track3) <- sample.names3
head(track3)

#Batch5
track5 <- cbind(out5, sapply(dadaFs5, getN), rowSums(seqtab5.nochim))
colnames(track5) <- c("input", "filtered", "denoisedF", "nonchim")
rownames(track5) <- sample.names5
head(track5)

```


### Assign Taxonomy
Taxonomy was assigned using the [Silva Taxonomic Training Data](https://zenodo.org/record/1172783#.YOb7KBNKiBQ). We used the assignment file to ensure exact matching to obtain the species data 
```{r Assign-Taxonomy}
#Batch1
taxa1 <- assignTaxonomy(seqtab1.nochim, here("Data", "Microbiome_Data", "silva_nr_v132_train_set.fa.gz"), multithread=TRUE)
taxa1 <- addSpecies(taxa1, here("Data", "Microbiome_Data", "silva_species_assignment_v132.fa.gz"))

#Batch2
taxa2 <- assignTaxonomy(seqtab2.nochim, here("Data", "Microbiome_Data", "silva_nr_v132_train_set.fa.gz"), multithread=TRUE)
taxa2 <- addSpecies(taxa2, here("Data", "Microbiome_Data", "silva_species_assignment_v132.fa.gz"))

#Batch3
taxa3 <- assignTaxonomy(seqtab3.nochim, here("Data", "Microbiome_Data", "silva_nr_v132_train_set.fa.gz"), multithread=TRUE)
taxa3 <- addSpecies(taxa3, here("Data", "Microbiome_Data", "silva_species_assignment_v132.fa.gz"))


#Batch5
taxa5 <- assignTaxonomy(seqtab5.nochim, here("Data", "Microbiome_Data", "silva_nr_v132_train_set.fa.gz"), multithread=TRUE)
taxa5 <- addSpecies(taxa5, here("Data", "Microbiome_Data", "silva_species_assignment_v132.fa.gz"))
```



## Creation of Phyloseq & Contaminant Removal
***
Phyloseq is a package designed to expidite the analysis of 16s sequencing results. Phyloseq objects are created after the sequences have been filtered, trimmed and assigned to taxonomy. 

### Batch Phyloseq objects
```{r Assign - Phyloseq}
#Step 1: Make Mapfile for each Batch 
#######################################################################

#Batch1
MapfileF1 <- Mapfile %>% filter(Mapfile$SampleID %in% sample.names1)
MapfileF1$Sample_or_Control <- ifelse(MapfileF1$ParticipantID == "NONE", "Control", "Sample")
MapfileF1$Batch <- 1
rownames(MapfileF1) <- MapfileF1$SampleID

#Batch2
MapfileF2 <- Mapfile %>% filter(Mapfile$SampleID %in% sample.names2)
MapfileF2$Sample_or_Control <- ifelse(MapfileF2$ParticipantID == "NONE", "Control", "Sample")
MapfileF2$Batch <- 2
rownames(MapfileF2) <- MapfileF2$SampleID

#Batch3
MapfileF3 <- Mapfile %>% filter(Mapfile$SampleID %in% sample.names3)
MapfileF3$Sample_or_Control <- ifelse(MapfileF3$ParticipantID == "NONE", "Control", "Sample")
MapfileF3$Batch <- 3
rownames(MapfileF3) <- MapfileF3$SampleID

#Batch5
MapfileF5 <- Mapfile %>% filter(Mapfile$SampleID %in% sample.names5)
MapfileF5$Sample_or_Control <- ifelse(MapfileF5$ParticipantID == "NONE", "Control", "Sample")
MapfileF5$Batch <- 5
rownames(MapfileF5) <- MapfileF5$SampleID


#Step 2: Assign Phyloseq for each Batch
#######################################################################

#Batch1
ps1 <- phyloseq(otu_table(seqtab1.nochim, taxa_are_rows=FALSE), 
               sample_data(MapfileF1), 
               tax_table(taxa1))

#Batch2
ps2 <- phyloseq(otu_table(seqtab2.nochim, taxa_are_rows=FALSE), 
               sample_data(MapfileF2), 
               tax_table(taxa2))

#Batch3
ps3 <- phyloseq(otu_table(seqtab3.nochim, taxa_are_rows=FALSE), 
               sample_data(MapfileF3), 
               tax_table(taxa3))

#Batch5
ps5 <- phyloseq(otu_table(seqtab5.nochim, taxa_are_rows=FALSE), 
               sample_data(MapfileF5), 
               tax_table(taxa5))

```


### Correct Controls via Decontam
The decontam package was designed to take phyloseq objects and correct experimental samples for contaminanting taxa. There are two methods. The prevalence method makes use of known controls while the frequency method looks at how often that marker appears across the samples. A threshold cutoff of 0.5 was used for the prevalence method to ensure OTUs appearing in higher prevalence in controls than samples are removed [tutorial](https://benjjneb.github.io/decontam/vignettes/decontam_intro.html)
```{r Decontam-Step1}
#Step 1: Inspect Library Sizes #######################################################################

#Batch1 
df1 <- as.data.frame(sample_data(ps1)) 
df1$LibrarySize <- sample_sums(ps1)
df1 <- df1[order(df1$LibrarySize),]
df1$Index <- seq(nrow(df1))
ggplot(data=df1, aes(x=Index, y=LibrarySize, color=Sample_or_Control)) + geom_point()

#Batch2
df2 <- as.data.frame(sample_data(ps2)) 
df2$LibrarySize <- sample_sums(ps2)
df2 <- df2[order(df2$LibrarySize),]
df2$Index <- seq(nrow(df2))
ggplot(data=df2, aes(x=Index, y=LibrarySize, color=Sample_or_Control)) + geom_point()

#Batch3
df3 <- as.data.frame(sample_data(ps3)) 
df3$LibrarySize <- sample_sums(ps3)
df3 <- df3[order(df3$LibrarySize),]
df3$Index <- seq(nrow(df3))
ggplot(data=df3, aes(x=Index, y=LibrarySize, color=Sample_or_Control)) + geom_point()

#Batch5
df5 <- as.data.frame(sample_data(ps5)) 
df5$LibrarySize <- sample_sums(ps5)
df5 <- df5[order(df5$LibrarySize),]
df5$Index <- seq(nrow(df5))
ggplot(data=df5, aes(x=Index, y=LibrarySize, color=Sample_or_Control)) + geom_point()


```


```{r Decontam-Step2}
#Step 2: Prevalence Method  #######################################################################
#Use a threshold of 0.5 to remove any taxa that are more prevalent in controls than in samples

#Batch1 ##########################################################
sample_data(ps1)$is.neg <- sample_data(ps1)$Sample_or_Control == "Control"
contamdf.prev1 <- isContaminant(ps1, method="prevalence", neg="is.neg")
table(contamdf.prev1$contaminant)
head(which(contamdf.prev1$contaminant))

#check with a 0.5 cutoff
contamdf.prev1.05 <- isContaminant(ps1, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev1.05$contaminant)

# Make phyloseq object of presence-absence in negative controls and true samples
ps1.pa <- transform_sample_counts(ps1, function(abund) 1*(abund>0))
ps1.pa.neg <- prune_samples(sample_data(ps1.pa)$Sample_or_Control == "Control", ps1.pa)
ps1.pa.pos <- prune_samples(sample_data(ps1.pa)$Sample_or_Control == "Sample", ps1.pa)

# Make data.frame of prevalence in positive and negative samples
df1.pa <- data.frame(pa.pos=taxa_sums(ps1.pa.pos), pa.neg=taxa_sums(ps1.pa.neg),
                      contaminant=contamdf.prev1.05$contaminant)
ggplot(data=df1.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)")

# Prune Taxa & Remove controls from phyloseq object
ps1.nocontamc <- prune_taxa(!contamdf.prev1.05$contaminant, ps1)
ps1.nocontam <- subset_samples(ps1.nocontamc, ParticipantID != "NONE")


#Batch2 ##########################################################
sample_data(ps2)$is.neg <- sample_data(ps2)$Sample_or_Control == "Control"
contamdf.prev2 <- isContaminant(ps2, method="prevalence", neg="is.neg")
table(contamdf.prev2$contaminant)
head(which(contamdf.prev2$contaminant))

#check with a 0.5 cutoff
contamdf.prev2.05 <- isContaminant(ps2, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev2.05$contaminant)

# Make phyloseq object of presence-absence in negative controls and true samples
ps2.pa <- transform_sample_counts(ps2, function(abund) 1*(abund>0))
ps2.pa.neg <- prune_samples(sample_data(ps2.pa)$Sample_or_Control == "Control", ps2.pa)
ps2.pa.pos <- prune_samples(sample_data(ps2.pa)$Sample_or_Control == "Sample", ps2.pa)

# Make data.frame of prevalence in positive and negative samples
df2.pa <- data.frame(pa.pos=taxa_sums(ps2.pa.pos), pa.neg=taxa_sums(ps2.pa.neg),
                      contaminant=contamdf.prev2.05$contaminant)
ggplot(data=df2.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)")

# Prune Taxa & Remove controls from phyloseq object
ps2.nocontamc <- prune_taxa(!contamdf.prev2.05$contaminant, ps2)
ps2.nocontam <- subset_samples(ps2.nocontamc, ParticipantID != "NONE")


#Batch3 ##########################################################
sample_data(ps3)$is.neg <- sample_data(ps3)$Sample_or_Control == "Control"
contamdf.prev3 <- isContaminant(ps3, method="prevalence", neg="is.neg")
table(contamdf.prev3$contaminant)
head(which(contamdf.prev3$contaminant))

#check with a 0.5 cutoff
contamdf.prev3.05 <- isContaminant(ps3, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev3.05$contaminant)

# Make phyloseq object of presence-absence in negative controls and true samples
ps3.pa <- transform_sample_counts(ps3, function(abund) 1*(abund>0))
ps3.pa.neg <- prune_samples(sample_data(ps3.pa)$Sample_or_Control == "Control", ps3.pa)
ps3.pa.pos <- prune_samples(sample_data(ps3.pa)$Sample_or_Control == "Sample", ps3.pa)

# Make data.frame of prevalence in positive and negative samples
df3.pa <- data.frame(pa.pos=taxa_sums(ps3.pa.pos), pa.neg=taxa_sums(ps3.pa.neg),
                      contaminant=contamdf.prev3.05$contaminant)
ggplot(data=df3.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)")

# Prune Taxa & Remove controls from phyloseq object
ps3.nocontamc <- prune_taxa(!contamdf.prev3.05$contaminant, ps3)
ps3.nocontam <- subset_samples(ps3.nocontamc, ParticipantID != "NONE")


#Batch5 ##########################################################
sample_data(ps5)$is.neg <- sample_data(ps5)$Sample_or_Control == "Control"
contamdf.prev5 <- isContaminant(ps5, method="prevalence", neg="is.neg")
table(contamdf.prev5$contaminant)
head(which(contamdf.prev5$contaminant))

#check with a 0.5 cutoff
contamdf.prev5.05 <- isContaminant(ps5, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev5.05$contaminant)

# Make phyloseq object of presence-absence in negative controls and true samples
ps5.pa <- transform_sample_counts(ps5, function(abund) 1*(abund>0))
ps5.pa.neg <- prune_samples(sample_data(ps5.pa)$Sample_or_Control == "Control", ps5.pa)
ps5.pa.pos <- prune_samples(sample_data(ps5.pa)$Sample_or_Control == "Sample", ps5.pa)

# Make data.frame of prevalence in positive and negative samples
df5.pa <- data.frame(pa.pos=taxa_sums(ps5.pa.pos), pa.neg=taxa_sums(ps5.pa.neg),
                      contaminant=contamdf.prev5.05$contaminant)
ggplot(data=df5.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)")

# Prune Taxa & Remove controls from phyloseq object
ps5.nocontamc <- prune_taxa(!contamdf.prev5.05$contaminant, ps5)
ps5.nocontam <- subset_samples(ps5.nocontamc, ParticipantID != "NONE")
```



## Batch Correction with CombatSeq  
[CombatSeq](https://pubmed.ncbi.nlm.nih.gov/33015620/) takes raw count matrices and uses a binomial regression to model batch effects. This requires a matrix with raw counts (the seqtab matrix made in the Construct Sequence Table tab) and a vector for batch separation. 3 Samples were removed that had total counts less than 2 (saved in rmsamples2). Note: another important step is removing samples with a library size less than 1355. This is the lowest number of reads/sample this function allows. CombatSeq also gets funky with 0-inflated data so its important to keep looking for alternative methods for batch correction
```{r CombatSeq-Batch-Correction}

#Step 1: Make variables for CombatSeq function 
#######################################################################

## Merge phyloseq
ps <- merge_phyloseq(ps1.nocontam, ps2.nocontam, ps3.nocontam, ps5.nocontam)

## Check object for any low count samples and remove ######################
combat1 <- as.data.frame(otu_table(ps))

combat2 <- t(combat1) ## Transpose first

libsize <- colSums(combat2)
#create new phyloseq object with removed samples ######################
#Remove sample with less than 10 counts
combatPS <- subset_samples(ps, ! sample_names(ps) %in% c("S522"))

combatps2 <- as.data.frame(otu_table(combatPS))

#Transpose
combat.ps2 <- t(combatps2)

#Create the batch Vector
batch <- sample_data(combatPS)$Batch

#Step 2: Batch Correction 
#######################################################################
# generate count table thats been corrected for batch effect
ps.adj <- ComBat_seq(counts=combat.ps2, batch=batch, group=NULL, full_mod = TRUE)

```



### Creating the final Phyloseq Object  
Here we use the final counts which have been corrected by control and by batch to create a final phyloseq object for downstream analysis. This requires an OTU counts table, sample datatable, and the taxanomic information tables. The phyloseq tree is added in after
```{r Create-Final-phyloseq, message=FALSE}
#Step 3: Prep to convert back into a phyloseq object
#######################################################################

#1. OTU counts table - CombatSeq output
ps.adj2 <- t(ps.adj)

#2. Sample data - pull from last edited phyloseq object and add in diet data results
MapfileM <- data.frame(sample_data(combatPS))
MapfileM2 <- dplyr::rename(MapfileM, redcapid = ParticipantID)
MapfileM3 <- subset(MapfileM2, select = -c(X, X.1, X.2, X.3, X.4 , X.5, X.6, X.7, 
                                          X.8, X.9, X.10, X.11, X.12, X.13, X.14, 
                                          X.15, X.16, X.17, X.18, X.19))

DietData <- read_csv(here("Output", "Diet_Output", "Demo_Diet_results.csv"))
MapfileDiet <- merge(MapfileM3, DietData, by = "redcapid")
SampleData <- sample_data(MapfileDiet)
rownames(SampleData) <- SampleData$SampleID

#3. Taxa tables - assign taxa to the adjusted table
taxaM <- assignTaxonomy(ps.adj2, here("Data", "Microbiome_Data", "silva_nr_v132_train_set.fa.gz"), 
                        multithread=TRUE)
taxaM <- addSpecies(taxaM, here("Data", "Microbiome_Data", "silva_species_assignment_v132.fa.gz"))


#Step 4: Combine into the final phyloseq object
#######################################################################
ps.f <- phyloseq(otu_table(ps.adj2, taxa_are_rows=FALSE), 
               sample_data(SampleData), 
               tax_table(taxaM))

```


Remove low count reads and those with less than 1% abundance in each sample
```{r}
#Step 1: Remove OTUs with less than 10 counts in all samples
#######################################################################
ps.fc <- filter_taxa(ps.f, function(x) sum(x) > 10, TRUE)
dim(otu_table(ps.fc))

#Step 2: Find taxa that appear in more than 1% of relative abundance
#######################################################################
ps.fr <- transform_sample_counts(ps.fc, function(x) x/sum(x))
ps.fr.p <- filter_taxa(ps.fr, function(x) sum(x) > .01, TRUE)
dim(otu_table(ps.fr.p))
otu_to_keep <- colnames(otu_table(ps.fr.p))

#Step 3: Make a normal count filter otutable to only include taxa from the 1% thats NOT transformed to relative abundance
#######################################################################
otu_to_filter <- data.frame(t(otu_table(ps.fc)))
otu_to_filter2 <- rownames_to_column(otu_to_filter, "OTU")
otu_filtered <- data.frame(subset(otu_to_filter2, OTU %in% otu_to_keep))
rownames(otu_filtered)<-NULL
otu_filtered2 <- column_to_rownames(otu_filtered, "OTU")
taxa_to_keep <- rownames(otu_filtered2)
otu_filtered3 <- t(otu_filtered2)

#Step 4: make filtered taxa object
#######################################################################
taxa_to_filter <- data.frame(tax_table(ps.fc))
taxa_to_filter <- rownames_to_column(taxa_to_filter, "OTU")
taxa_filtered <- subset(taxa_to_filter, OTU %in% taxa_to_keep)
rownames(taxa_filtered)<-NULL
taxa_filtered2 <- column_to_rownames(taxa_filtered, "OTU")
taxa_filtered3 <- as.matrix(taxa_filtered2)

#Step 5: Assign filtered counts to phyloseq
#######################################################################
ps.f <- phyloseq(otu_table(otu_filtered3, taxa_are_rows = FALSE), 
               sample_data(SampleData), 
               tax_table(taxa_filtered3))


write.csv(data.frame(SampleData), here("Output", "Microbiome_Output", "Sample_Data_duplicates.csv"))
```


Add in the phyloseq tree and remove duplicate samples
```{r}
#Step 6: add in phylo tree using the "ape" package
#######################################################################
phy_tree <- rtree(ntaxa(ps.f), rooted=TRUE, tip.label=taxa_names(ps.f))
ps.f <- merge_phyloseq(ps.f, phy_tree)


#Step 7: Remove duplicate samples 
#######################################################################
ps.f <- subset_samples(ps.f, SampleID != "S169" & SampleID !="S406" & 
                         SampleID !="S279" & SampleID !="S533" & SampleID !="S554" &
                         SampleID !="S669" & SampleID !="S672")
dim(otu_table(ps.f))

write.csv(data.frame(SampleData), here("Output", "Microbiome_Output", "Sample_Data.csv"))
```


Save final Phyloseq object to read in to the analysis scripts
```{r}
#SaveRDS so we can call back in the object without repeat the analysis for 
#######################################################################
saveRDS(ps.f, here("Output", "Microbiome_Output", "Phyloseq_Objects", "ps.rds"))
```


